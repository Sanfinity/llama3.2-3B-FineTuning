# Fine-Tuning LLaMA 3.2 with Custom Application Diagnostics Data

## Overview
This repository contains a fine-tuning workflow for **LLaMA 3.2 (1B & 3B models)** using **Unsloth**. It is based on the official Unsloth training notebook but modified to incorporate **custom diagnostic data** generated by **latest LLMs like Grok and DeepSeek**.

## Modifications and Enhancements
- **Custom Data Integration:**
  - Replaced the original dataset with a **custom dataset** stored in a `.txt` file.
  - The dataset contains **application diagnostics information**, generated using state-of-the-art LLMs.
- **Data Preprocessing:**
  - Mounted Google Drive and imported the dataset.
  - Converted the dataset into **Hugging Face's multi-turn format** (role-based conversation structure).
  - Applied **LLaMA 3.1 chat templates** to ensure proper formatting.
- **Model Training:**
  - Used **Unsloth's fine-tuning framework** to train the LLaMA models.
  - Configured `SFTTrainer` with optimized hyperparameters.
- **Model Saving:**
  - Trained models were **saved directly to Google Drive** for easy access and storage.

## How to Use
1. **Clone this repository**:
   ```bash
   git clone https://github.com/Sanfinity/llama3.2-3B-FineTuning
   cd llama3.2-3B-FineTuning
   ```
2. **Run the training notebook** in Colab or a local Jupyter environment.
3. **Modify `data.txt`** to use your own dataset if needed.
4. **Access trained models from Google Drive** or upload them to Hugging Face Hub.

## Acknowledgments
- The base notebook was adapted from **Unsloth's official LLaMA 3.2 fine-tuning guide**.
- Special thanks to **Meta, Unsloth, Hugging Face**, and the broader **open-source LLM community**.

## Next Steps
- Further refine the dataset with **real-world diagnostic logs**.
- Experiment with **LoRA & QLoRA** for efficient training.
- Explore **deployment strategies** for real-time inference.

## Tips & Tricks
- Try using Google colab as that seems to be the only reliable option to train llms easily for free.
- If you have a RTX4090, burn it down ðŸ”¥
---
ðŸš€ **Happy Fine-Tuning!**

